{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpBPPKhvdO19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imOSciWcwUHb",
        "outputId": "8f075ef0-0f65-421a-b2e0-013a5ffa1960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 6413 samples, validate on 1604 samples\n",
            "Epoch 1/100\n",
            "6016/6413 [===========================>..] - ETA: 0s - loss: 538.7672 - accuracy: 0.5181"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2333: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r6413/6413 [==============================] - 2s 235us/sample - loss: 669.5241 - accuracy: 0.5165 - val_loss: 5068.8773 - val_accuracy: 0.4302\n",
            "Epoch 2/100\n",
            "6413/6413 [==============================] - 1s 89us/sample - loss: 2575.6060 - accuracy: 0.5104 - val_loss: 2874.1279 - val_accuracy: 0.5773\n",
            "Epoch 3/100\n",
            "6413/6413 [==============================] - 1s 92us/sample - loss: 2882.2121 - accuracy: 0.5158 - val_loss: 641.0802 - val_accuracy: 0.5380\n",
            "Epoch 4/100\n",
            "6413/6413 [==============================] - 1s 87us/sample - loss: 2011.5351 - accuracy: 0.5244 - val_loss: 2126.8567 - val_accuracy: 0.3653\n",
            "Epoch 5/100\n",
            "6413/6413 [==============================] - 1s 87us/sample - loss: 971.5426 - accuracy: 0.5467 - val_loss: 844.7160 - val_accuracy: 0.5455\n",
            "Epoch 6/100\n",
            "6413/6413 [==============================] - 1s 88us/sample - loss: 1439.3860 - accuracy: 0.5409 - val_loss: 84.2500 - val_accuracy: 0.5542\n",
            "Epoch 7/100\n",
            "6413/6413 [==============================] - 1s 94us/sample - loss: 2312.3768 - accuracy: 0.5547 - val_loss: 546.5802 - val_accuracy: 0.4988\n",
            "Epoch 8/100\n",
            "6413/6413 [==============================] - 1s 92us/sample - loss: 1597.0556 - accuracy: 0.5643 - val_loss: 4469.1492 - val_accuracy: 0.4738\n",
            "Epoch 9/100\n",
            "6413/6413 [==============================] - 1s 102us/sample - loss: 1626.4863 - accuracy: 0.5685 - val_loss: 3038.0872 - val_accuracy: 0.6446\n",
            "Epoch 10/100\n",
            "6413/6413 [==============================] - 1s 154us/sample - loss: 1988.4964 - accuracy: 0.5897 - val_loss: 2246.0538 - val_accuracy: 0.4327\n",
            "Epoch 11/100\n",
            "6413/6413 [==============================] - 1s 141us/sample - loss: 746.8077 - accuracy: 0.5968 - val_loss: 1520.0854 - val_accuracy: 0.6185\n",
            "Epoch 12/100\n",
            "6413/6413 [==============================] - 1s 146us/sample - loss: 604.3307 - accuracy: 0.5939 - val_loss: 2566.3143 - val_accuracy: 0.4875\n",
            "Epoch 13/100\n",
            "6413/6413 [==============================] - 1s 102us/sample - loss: 210.2916 - accuracy: 0.6194 - val_loss: 540.8921 - val_accuracy: 0.5505\n",
            "Epoch 14/100\n",
            "6413/6413 [==============================] - 1s 92us/sample - loss: 895.3219 - accuracy: 0.6119 - val_loss: 88.8147 - val_accuracy: 0.4526\n",
            "Epoch 15/100\n",
            "6413/6413 [==============================] - 1s 89us/sample - loss: 1552.3775 - accuracy: 0.6259 - val_loss: 2275.3305 - val_accuracy: 0.4084\n",
            "Epoch 16/100\n",
            "6413/6413 [==============================] - 1s 88us/sample - loss: 1047.0197 - accuracy: 0.6387 - val_loss: 2567.0444 - val_accuracy: 0.3847\n",
            "Epoch 17/100\n",
            "6413/6413 [==============================] - 1s 85us/sample - loss: 504.4361 - accuracy: 0.6604 - val_loss: 311.9670 - val_accuracy: 0.4464\n",
            "Epoch 18/100\n",
            "6413/6413 [==============================] - 1s 98us/sample - loss: 478.0564 - accuracy: 0.6474 - val_loss: 5.8234 - val_accuracy: 0.4133\n",
            "Epoch 19/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 150.2763 - accuracy: 0.6449 - val_loss: 35.6066 - val_accuracy: 0.4389\n",
            "Epoch 20/100\n",
            "6413/6413 [==============================] - 1s 87us/sample - loss: 480.3586 - accuracy: 0.6406 - val_loss: 281.3215 - val_accuracy: 0.4900\n",
            "Epoch 21/100\n",
            "6413/6413 [==============================] - 1s 95us/sample - loss: 433.3145 - accuracy: 0.6629 - val_loss: 328.1592 - val_accuracy: 0.5224\n",
            "Epoch 22/100\n",
            "6413/6413 [==============================] - 1s 86us/sample - loss: 483.2146 - accuracy: 0.6524 - val_loss: 652.5505 - val_accuracy: 0.4121\n",
            "Epoch 23/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 455.2048 - accuracy: 0.6615 - val_loss: 714.2137 - val_accuracy: 0.5025\n",
            "Epoch 24/100\n",
            "6413/6413 [==============================] - 1s 86us/sample - loss: 0.6285 - accuracy: 0.6587 - val_loss: 1.0770 - val_accuracy: 0.4688\n",
            "Epoch 25/100\n",
            "6413/6413 [==============================] - 1s 94us/sample - loss: 0.6584 - accuracy: 0.6694 - val_loss: 0.9611 - val_accuracy: 0.4470\n",
            "Epoch 26/100\n",
            "6413/6413 [==============================] - 1s 90us/sample - loss: 13.4961 - accuracy: 0.6710 - val_loss: 1.1668 - val_accuracy: 0.4875\n",
            "Epoch 27/100\n",
            "6413/6413 [==============================] - 1s 86us/sample - loss: 4.3459 - accuracy: 0.6782 - val_loss: 1076.7352 - val_accuracy: 0.4557\n",
            "Epoch 28/100\n",
            "6413/6413 [==============================] - 1s 108us/sample - loss: 609.3397 - accuracy: 0.6686 - val_loss: 1363.9171 - val_accuracy: 0.3853\n",
            "Epoch 29/100\n",
            "6413/6413 [==============================] - 1s 112us/sample - loss: 291.3362 - accuracy: 0.6875 - val_loss: 39.6198 - val_accuracy: 0.5193\n",
            "Epoch 30/100\n",
            "6413/6413 [==============================] - 1s 139us/sample - loss: 2.7718 - accuracy: 0.6632 - val_loss: 1.6506 - val_accuracy: 0.6615\n",
            "Epoch 31/100\n",
            "6413/6413 [==============================] - 1s 177us/sample - loss: 0.6641 - accuracy: 0.6916 - val_loss: 1.0221 - val_accuracy: 0.4994\n",
            "Epoch 32/100\n",
            "6413/6413 [==============================] - 1s 134us/sample - loss: 0.8344 - accuracy: 0.6839 - val_loss: 0.9798 - val_accuracy: 0.5268\n",
            "Epoch 33/100\n",
            "6413/6413 [==============================] - 1s 125us/sample - loss: 3.5319 - accuracy: 0.6998 - val_loss: 54.3644 - val_accuracy: 0.4214\n",
            "Epoch 34/100\n",
            "6413/6413 [==============================] - 1s 95us/sample - loss: 27.0691 - accuracy: 0.6870 - val_loss: 0.9734 - val_accuracy: 0.3797\n",
            "Epoch 35/100\n",
            "6413/6413 [==============================] - 1s 111us/sample - loss: 0.6603 - accuracy: 0.6805 - val_loss: 1.0304 - val_accuracy: 0.4077\n",
            "Epoch 36/100\n",
            "6413/6413 [==============================] - 1s 114us/sample - loss: 18.0525 - accuracy: 0.6883 - val_loss: 1.4000 - val_accuracy: 0.5786\n",
            "Epoch 37/100\n",
            "6413/6413 [==============================] - 1s 92us/sample - loss: 45.3508 - accuracy: 0.6941 - val_loss: 0.9106 - val_accuracy: 0.5200\n",
            "Epoch 38/100\n",
            "6413/6413 [==============================] - 1s 86us/sample - loss: 0.7139 - accuracy: 0.6908 - val_loss: 0.9270 - val_accuracy: 0.4015\n",
            "Epoch 39/100\n",
            "6413/6413 [==============================] - 1s 101us/sample - loss: 0.8440 - accuracy: 0.7070 - val_loss: 1.0016 - val_accuracy: 0.4670\n",
            "Epoch 40/100\n",
            "6413/6413 [==============================] - 1s 115us/sample - loss: 0.5781 - accuracy: 0.6930 - val_loss: 105.8923 - val_accuracy: 0.5530\n",
            "Epoch 41/100\n",
            "6413/6413 [==============================] - 1s 113us/sample - loss: 12.3295 - accuracy: 0.6959 - val_loss: 22.1285 - val_accuracy: 0.5393\n",
            "Epoch 42/100\n",
            "6413/6413 [==============================] - 1s 93us/sample - loss: 0.5435 - accuracy: 0.6944 - val_loss: 0.9442 - val_accuracy: 0.5711\n",
            "Epoch 43/100\n",
            "6413/6413 [==============================] - 1s 93us/sample - loss: 0.5314 - accuracy: 0.7001 - val_loss: 0.8993 - val_accuracy: 0.4140\n",
            "Epoch 44/100\n",
            "6413/6413 [==============================] - 1s 84us/sample - loss: 0.5667 - accuracy: 0.6995 - val_loss: 0.9695 - val_accuracy: 0.4526\n",
            "Epoch 45/100\n",
            "6413/6413 [==============================] - 1s 100us/sample - loss: 0.5780 - accuracy: 0.7065 - val_loss: 0.9012 - val_accuracy: 0.5848\n",
            "Epoch 46/100\n",
            "6413/6413 [==============================] - 1s 104us/sample - loss: 0.5371 - accuracy: 0.6869 - val_loss: 1.1136 - val_accuracy: 0.3928\n",
            "Epoch 47/100\n",
            "6413/6413 [==============================] - 1s 107us/sample - loss: 0.5346 - accuracy: 0.7019 - val_loss: 1.0741 - val_accuracy: 0.5424\n",
            "Epoch 48/100\n",
            "6413/6413 [==============================] - 1s 182us/sample - loss: 0.7039 - accuracy: 0.7073 - val_loss: 1.1614 - val_accuracy: 0.5337\n",
            "Epoch 49/100\n",
            "6413/6413 [==============================] - 1s 150us/sample - loss: 0.5871 - accuracy: 0.6992 - val_loss: 5.7918 - val_accuracy: 0.6066\n",
            "Epoch 50/100\n",
            "6413/6413 [==============================] - 1s 146us/sample - loss: 1.0420 - accuracy: 0.7073 - val_loss: 1.0470 - val_accuracy: 0.4551\n",
            "Epoch 51/100\n",
            "6413/6413 [==============================] - 1s 111us/sample - loss: 0.5369 - accuracy: 0.7072 - val_loss: 1.0944 - val_accuracy: 0.3959\n",
            "Epoch 52/100\n",
            "6413/6413 [==============================] - 1s 90us/sample - loss: 43.7997 - accuracy: 0.7137 - val_loss: 0.9885 - val_accuracy: 0.4988\n",
            "Epoch 53/100\n",
            "6413/6413 [==============================] - 1s 90us/sample - loss: 13.3274 - accuracy: 0.7111 - val_loss: 1.3162 - val_accuracy: 0.5517\n",
            "Epoch 54/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 0.5311 - accuracy: 0.7132 - val_loss: 1.0451 - val_accuracy: 0.4102\n",
            "Epoch 55/100\n",
            "6413/6413 [==============================] - 1s 93us/sample - loss: 13.0348 - accuracy: 0.7176 - val_loss: 0.9599 - val_accuracy: 0.4370\n",
            "Epoch 56/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 0.7955 - accuracy: 0.7213 - val_loss: 1.2156 - val_accuracy: 0.3965\n",
            "Epoch 57/100\n",
            "6413/6413 [==============================] - 1s 88us/sample - loss: 0.6621 - accuracy: 0.7223 - val_loss: 1.2041 - val_accuracy: 0.5829\n",
            "Epoch 58/100\n",
            "6413/6413 [==============================] - 1s 89us/sample - loss: 0.5294 - accuracy: 0.7187 - val_loss: 1.0476 - val_accuracy: 0.4034\n",
            "Epoch 59/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 0.5907 - accuracy: 0.7157 - val_loss: 1.2581 - val_accuracy: 0.4084\n",
            "Epoch 60/100\n",
            "6413/6413 [==============================] - 1s 92us/sample - loss: 0.5385 - accuracy: 0.7139 - val_loss: 0.9205 - val_accuracy: 0.4370\n",
            "Epoch 61/100\n",
            "6413/6413 [==============================] - 1s 90us/sample - loss: 0.5215 - accuracy: 0.7104 - val_loss: 0.8711 - val_accuracy: 0.4339\n",
            "Epoch 62/100\n",
            "6413/6413 [==============================] - 1s 90us/sample - loss: 0.5079 - accuracy: 0.7164 - val_loss: 0.9660 - val_accuracy: 0.4589\n",
            "Epoch 63/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 8.1692 - accuracy: 0.7291 - val_loss: 1.0101 - val_accuracy: 0.4065\n",
            "Epoch 64/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 6.6021 - accuracy: 0.7358 - val_loss: 0.9666 - val_accuracy: 0.4638\n",
            "Epoch 65/100\n",
            "6413/6413 [==============================] - 1s 103us/sample - loss: 12.2412 - accuracy: 0.7281 - val_loss: 1.1088 - val_accuracy: 0.4919\n",
            "Epoch 66/100\n",
            "6413/6413 [==============================] - 1s 116us/sample - loss: 2.7026 - accuracy: 0.7385 - val_loss: 1.1190 - val_accuracy: 0.3915\n",
            "Epoch 67/100\n",
            "6413/6413 [==============================] - 1s 179us/sample - loss: 1.8973 - accuracy: 0.7362 - val_loss: 1.5041 - val_accuracy: 0.6347\n",
            "Epoch 68/100\n",
            "6413/6413 [==============================] - 1s 174us/sample - loss: 1.3463 - accuracy: 0.7305 - val_loss: 1.1648 - val_accuracy: 0.6546\n",
            "Epoch 69/100\n",
            "6413/6413 [==============================] - 1s 154us/sample - loss: 0.5956 - accuracy: 0.7327 - val_loss: 0.9375 - val_accuracy: 0.4744\n",
            "Epoch 70/100\n",
            "6413/6413 [==============================] - 1s 117us/sample - loss: 6.0933 - accuracy: 0.7312 - val_loss: 1.2055 - val_accuracy: 0.5567\n",
            "Epoch 71/100\n",
            "6413/6413 [==============================] - 1s 95us/sample - loss: 19.0330 - accuracy: 0.7341 - val_loss: 1.1528 - val_accuracy: 0.4738\n",
            "Epoch 72/100\n",
            "6413/6413 [==============================] - 1s 99us/sample - loss: 0.6045 - accuracy: 0.7421 - val_loss: 162.5516 - val_accuracy: 0.4994\n",
            "Epoch 73/100\n",
            "6413/6413 [==============================] - 1s 108us/sample - loss: 3.2064 - accuracy: 0.7323 - val_loss: 1.1829 - val_accuracy: 0.5312\n",
            "Epoch 74/100\n",
            "6413/6413 [==============================] - 1s 118us/sample - loss: 0.4847 - accuracy: 0.7432 - val_loss: 1.1680 - val_accuracy: 0.4084\n",
            "Epoch 75/100\n",
            "6413/6413 [==============================] - 1s 104us/sample - loss: 519.3809 - accuracy: 0.7228 - val_loss: 28.7810 - val_accuracy: 0.5480\n",
            "Epoch 76/100\n",
            "6413/6413 [==============================] - 1s 105us/sample - loss: 9.2807 - accuracy: 0.7215 - val_loss: 1.0792 - val_accuracy: 0.4308\n",
            "Epoch 77/100\n",
            "6413/6413 [==============================] - 1s 125us/sample - loss: 13.9552 - accuracy: 0.7217 - val_loss: 57.4422 - val_accuracy: 0.4695\n",
            "Epoch 78/100\n",
            "6413/6413 [==============================] - 1s 118us/sample - loss: 17.8191 - accuracy: 0.7274 - val_loss: 44.1545 - val_accuracy: 0.4133\n",
            "Epoch 79/100\n",
            "6413/6413 [==============================] - 1s 114us/sample - loss: 32.3492 - accuracy: 0.7313 - val_loss: 12.3816 - val_accuracy: 0.4308\n",
            "Epoch 80/100\n",
            "6413/6413 [==============================] - 1s 125us/sample - loss: 6.6802 - accuracy: 0.7268 - val_loss: 4.5006 - val_accuracy: 0.4956\n",
            "Epoch 81/100\n",
            "6413/6413 [==============================] - 1s 119us/sample - loss: 9.8560 - accuracy: 0.7338 - val_loss: 0.9945 - val_accuracy: 0.5480\n",
            "Epoch 82/100\n",
            "6413/6413 [==============================] - 1s 110us/sample - loss: 0.7549 - accuracy: 0.7394 - val_loss: 0.8655 - val_accuracy: 0.4819\n",
            "Epoch 83/100\n",
            "6413/6413 [==============================] - 1s 138us/sample - loss: 0.4857 - accuracy: 0.7418 - val_loss: 0.9477 - val_accuracy: 0.4395\n",
            "Epoch 84/100\n",
            "6413/6413 [==============================] - 1s 144us/sample - loss: 0.4787 - accuracy: 0.7365 - val_loss: 1.1481 - val_accuracy: 0.4034\n",
            "Epoch 85/100\n",
            "6413/6413 [==============================] - 1s 148us/sample - loss: 1.0192 - accuracy: 0.7383 - val_loss: 1.4806 - val_accuracy: 0.3666\n",
            "Epoch 86/100\n",
            "6413/6413 [==============================] - 1s 108us/sample - loss: 209.5480 - accuracy: 0.7265 - val_loss: 81.6347 - val_accuracy: 0.5729\n",
            "Epoch 87/100\n",
            "6413/6413 [==============================] - 1s 107us/sample - loss: 30.5342 - accuracy: 0.7327 - val_loss: 58.6767 - val_accuracy: 0.5586\n",
            "Epoch 88/100\n",
            "6413/6413 [==============================] - 1s 103us/sample - loss: 64.7364 - accuracy: 0.7348 - val_loss: 13.0650 - val_accuracy: 0.4925\n",
            "Epoch 89/100\n",
            "6413/6413 [==============================] - 1s 95us/sample - loss: 36.4331 - accuracy: 0.7436 - val_loss: 19.1115 - val_accuracy: 0.6085\n",
            "Epoch 90/100\n",
            "6413/6413 [==============================] - 1s 108us/sample - loss: 229.6010 - accuracy: 0.7422 - val_loss: 1.2133 - val_accuracy: 0.5642\n",
            "Epoch 91/100\n",
            "6413/6413 [==============================] - 1s 113us/sample - loss: 4.1835 - accuracy: 0.7446 - val_loss: 120.6498 - val_accuracy: 0.5281\n",
            "Epoch 92/100\n",
            "6413/6413 [==============================] - 1s 111us/sample - loss: 0.5611 - accuracy: 0.7466 - val_loss: 0.9868 - val_accuracy: 0.5249\n",
            "Epoch 93/100\n",
            "6413/6413 [==============================] - 1s 99us/sample - loss: 0.8116 - accuracy: 0.7438 - val_loss: 10.0093 - val_accuracy: 0.3903\n",
            "Epoch 94/100\n",
            "6413/6413 [==============================] - 1s 100us/sample - loss: 0.9462 - accuracy: 0.7482 - val_loss: 1.2870 - val_accuracy: 0.6652\n",
            "Epoch 95/100\n",
            "6413/6413 [==============================] - 1s 91us/sample - loss: 0.4814 - accuracy: 0.7405 - val_loss: 0.9734 - val_accuracy: 0.4757\n",
            "Epoch 96/100\n",
            "6413/6413 [==============================] - 1s 99us/sample - loss: 0.7240 - accuracy: 0.7514 - val_loss: 4.0740 - val_accuracy: 0.6166\n",
            "Epoch 97/100\n",
            "6413/6413 [==============================] - 1s 98us/sample - loss: 52.6824 - accuracy: 0.7489 - val_loss: 3.3007 - val_accuracy: 0.6714\n",
            "Epoch 98/100\n",
            "6413/6413 [==============================] - 1s 95us/sample - loss: 192.0359 - accuracy: 0.7374 - val_loss: 44.0440 - val_accuracy: 0.4757\n",
            "Epoch 99/100\n",
            "6413/6413 [==============================] - 1s 102us/sample - loss: 19.9383 - accuracy: 0.7461 - val_loss: 1.0482 - val_accuracy: 0.6097\n",
            "Epoch 100/100\n",
            "6413/6413 [==============================] - 1s 118us/sample - loss: 0.4581 - accuracy: 0.7532 - val_loss: 1.0202 - val_accuracy: 0.6266\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Dense\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from keras import backend as K\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Dataset1.csv')\n",
        "#data = pd.read_csv('/content/Dataset2.csv')\n",
        "\n",
        "# Pre-processing\n",
        "# Remove any rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Split the data into features and labels\n",
        "features = data.iloc[:, :-1].values\n",
        "labels = data.iloc[:, -1].values\n",
        "\n",
        "# One-hot encode the labels\n",
        "labels = np_utils.to_categorical(labels)\n",
        "\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "\n",
        "\n",
        "# Reshape the features to 3D arrays\n",
        "features = np.reshape(features, (features.shape[0], 1, features.shape[1]))\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(features.shape[1], features.shape[2]), activation='relu', return_sequences=True))\n",
        "model.add(GRU(32, activation='relu'))\n",
        "model.add(Dense(labels.shape[1], activation='softmax'))\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer='RMSProp', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Disable eager execution\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Train the model\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    history = model.fit(features, labels, epochs=100, batch_size=32, verbose=1, validation_split=0.2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ktrh3_yYYo_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "uDd5TOcXUQXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply rolling average with window size of 10\n",
        "rolling_window_size = 10\n",
        "train_loss_smooth = np.convolve(history.history['loss'], np.ones(rolling_window_size)/rolling_window_size, mode='valid')\n",
        "val_loss_smooth = np.convolve(history.history['val_loss'], np.ones(rolling_window_size)/rolling_window_size, mode='valid')\n",
        "\n",
        "# Plot the smoothed curves with color and line type customization\n",
        "plt.plot(train_loss_smooth, 'r--')\n",
        "plt.plot(val_loss_smooth, 'b-')\n",
        "#plt.title('Model Accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "27TedlC2yygB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import savgol_filter\n",
        "\n",
        "train_acc_smooth = savgol_filter(history.history['accuracy'], 15, 3)\n",
        "val_acc_smooth = savgol_filter(history.history['val_accuracy'], 15, 3)\n",
        "\n",
        "plt.plot(train_acc_smooth, 'r--')\n",
        "plt.plot(val_acc_smooth, 'b-')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'], loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MxvgD8vs_xog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yX_F5iPFKtli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model\n",
        "#history = model.fit(features, labels, epochs=100, batch_size=32, verbose=0, validation_split=0.2)\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Noy0WM6K2VIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rolling_window_size = 10\n",
        "train_loss_smooth = np.convolve(history.history['loss'], np.ones(rolling_window_size)/rolling_window_size, mode='valid')\n",
        "val_loss_smooth = np.convolve(history.history['val_loss'], np.ones(rolling_window_size)/rolling_window_size, mode='valid')\n",
        "\n",
        "# Plot the smoothed curves\n",
        "plt.plot(train_loss_smooth)\n",
        "plt.plot(val_loss_smooth)\n",
        "#plt.title('Model Accuracy')\n",
        "plt.plot(train_loss_smooth, 'g-')\n",
        "plt.plot(val_loss_smooth, 'b.')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BW0L0McW2mQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import savgol_filter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Smooth the training and validation loss curves\n",
        "train_loss_smooth = savgol_filter(history.history['loss'], 51, 3)\n",
        "val_loss_smooth = savgol_filter(history.history['val_loss'], 51, 3)\n",
        "\n",
        "# Plot the smoothed curves\n",
        "plt.plot(train_loss_smooth, color='green')\n",
        "plt.plot(val_loss_smooth, color='blue')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hxLJjUUf-_Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train the model\n",
        "#history = model.fit(features, labels, epochs=100, batch_size=32, verbose=0, validation_split=0.2)\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.plot(history.history['precision_score'])\n",
        "plt.plot(history.history['recall_score'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iGv6Llr22tuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}